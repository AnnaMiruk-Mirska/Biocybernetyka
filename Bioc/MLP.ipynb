{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron (MLP) for multi-class softmax classification (Keras Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "decay is deprecated in the new Keras optimizer, please check the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.SGD.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(number_of_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Model Compilation. Loss for multi-class classification problem\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m sgd \u001b[38;5;241m=\u001b[39m \u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m rmsprop \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     44\u001b[0m adam \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\PycharmProjects\\ImageEditor\\venv\\lib\\site-packages\\keras\\src\\optimizers\\sgd.py:114\u001b[0m, in \u001b[0;36mSGD.__init__\u001b[1;34m(self, learning_rate, momentum, nesterov, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, name, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    100\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    113\u001b[0m ):\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    115\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    116\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    117\u001b[0m         clipnorm\u001b[38;5;241m=\u001b[39mclipnorm,\n\u001b[0;32m    118\u001b[0m         clipvalue\u001b[38;5;241m=\u001b[39mclipvalue,\n\u001b[0;32m    119\u001b[0m         global_clipnorm\u001b[38;5;241m=\u001b[39mglobal_clipnorm,\n\u001b[0;32m    120\u001b[0m         use_ema\u001b[38;5;241m=\u001b[39muse_ema,\n\u001b[0;32m    121\u001b[0m         ema_momentum\u001b[38;5;241m=\u001b[39mema_momentum,\n\u001b[0;32m    122\u001b[0m         ema_overwrite_frequency\u001b[38;5;241m=\u001b[39mema_overwrite_frequency,\n\u001b[0;32m    123\u001b[0m         jit_compile\u001b[38;5;241m=\u001b[39mjit_compile,\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    125\u001b[0m     )\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_learning_rate(learning_rate)\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;241m=\u001b[39m momentum\n",
      "File \u001b[1;32m~\\PycharmProjects\\ImageEditor\\venv\\lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1084\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[0;32m   1082\u001b[0m mesh \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmesh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mesh \u001b[38;5;241m=\u001b[39m mesh\n\u001b[1;32m-> 1084\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   1085\u001b[0m     name,\n\u001b[0;32m   1086\u001b[0m     weight_decay,\n\u001b[0;32m   1087\u001b[0m     clipnorm,\n\u001b[0;32m   1088\u001b[0m     clipvalue,\n\u001b[0;32m   1089\u001b[0m     global_clipnorm,\n\u001b[0;32m   1090\u001b[0m     use_ema,\n\u001b[0;32m   1091\u001b[0m     ema_momentum,\n\u001b[0;32m   1092\u001b[0m     ema_overwrite_frequency,\n\u001b[0;32m   1093\u001b[0m     jit_compile,\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1095\u001b[0m )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_with_dtensor \u001b[38;5;241m=\u001b[39m dtensor_utils\u001b[38;5;241m.\u001b[39mrunning_with_dtensor_strategy()\n",
      "File \u001b[1;32m~\\PycharmProjects\\ImageEditor\\venv\\lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:106\u001b[0m, in \u001b[0;36m_BaseOptimizer.__init__\u001b[1;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_iteration_variable()\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\ImageEditor\\venv\\lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:135\u001b[0m, in \u001b[0;36m_BaseOptimizer._process_kwargs\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m legacy_kwargs:\n\u001b[1;32m--> 135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    136\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated in the new Keras optimizer, please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck the docstring for valid arguments, or use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy optimizer, e.g., \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.keras.optimizers.legacy.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m         )\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    143\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid argument, kwargs should be empty \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for `optimizer_experimental.Optimizer`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: decay is deprecated in the new Keras optimizer, please check the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.SGD."
     ]
    }
   ],
   "source": [
    "# coding= UTF-8\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fix random seed number\n",
    "np.random.seed(7)\n",
    "\n",
    "# Load the data\n",
    "X = np.load('feat.npy')\n",
    "y = np.load('label.npy').ravel() #Return a contiguous flattened array.\n",
    "\n",
    "number_of_features = len(X[1]) #This is variable with each run\n",
    "number_of_classes = 3\n",
    "\n",
    "# Sample data randomly\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) #70% Train, 30% Test\n",
    "\n",
    "# Neural Network Architecture\n",
    "model = Sequential() # Define Sequential model\n",
    "\n",
    "# Using relu on the first two layers and softmax on the output layer\n",
    "\n",
    "# 1st Layer\n",
    "#N neurons, Number_Fatures-dimensional vectors\n",
    "model.add(Dense(512, input_dim=number_of_features, activation='relu')) #32, 64, 128, 256, 512, 1024\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 2nd Layer\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 3rd Layer. Output 3 neurons corresponding the number of classes\n",
    "# The sigmoid function is used for the two-class logistic regression, \n",
    "# whereas the softmax function is used for the multiclass logistic regression \n",
    "model.add(Dense(number_of_classes, activation='softmax'))\n",
    "\n",
    "# Model Compilation. Loss for multi-class classification problem\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rmsprop = 'rmsprop'\n",
    "adam = 'adam'\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= rmsprop, #rmsprop better than sgd\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train-1, num_classes= number_of_classes) # Convert class vector into binary Matrix\n",
    "y_test = keras.utils.to_categorical(y_test-1, num_classes= number_of_classes)\n",
    "\n",
    "# Train and test\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=64) #batch 32, 64, 128, 256, 512\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Test score:', score\n",
    "print'Test accuracy:', acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
