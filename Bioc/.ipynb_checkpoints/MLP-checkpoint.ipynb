{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron (MLP) for multi-class softmax classification (Keras Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'feat.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeat.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;66;03m#Return a contiguous flattened array.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m number_of_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;66;03m#This is variable with each run\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\ImageEditor\\venv\\lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'feat.npy'"
     ]
    }
   ],
   "source": [
    "# coding= UTF-8\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fix random seed number\n",
    "np.random.seed(7)\n",
    "\n",
    "# Load the data\n",
    "X = np.load('feat.npy')\n",
    "y = np.load('label.npy').ravel() #Return a contiguous flattened array.\n",
    "\n",
    "number_of_features = len(X[1]) #This is variable with each run\n",
    "number_of_classes = 3\n",
    "\n",
    "# Sample data randomly\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) #70% Train, 30% Test\n",
    "\n",
    "# Neural Network Architecture\n",
    "model = Sequential() # Define Sequential model\n",
    "\n",
    "# Using relu on the first two layers and softmax on the output layer\n",
    "\n",
    "# 1st Layer\n",
    "#N neurons, Number_Fatures-dimensional vectors\n",
    "model.add(Dense(512, input_dim=number_of_features, activation='relu')) #32, 64, 128, 256, 512, 1024\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 2nd Layer\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 3rd Layer. Output 3 neurons corresponding the number of classes\n",
    "# The sigmoid function is used for the two-class logistic regression, \n",
    "# whereas the softmax function is used for the multiclass logistic regression \n",
    "model.add(Dense(number_of_classes, activation='softmax'))\n",
    "\n",
    "# Model Compilation. Loss for multi-class classification problem\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rmsprop = 'rmsprop'\n",
    "adam = 'adam'\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= rmsprop, #rmsprop better than sgd\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train-1, num_classes= number_of_classes) # Convert class vector into binary Matrix\n",
    "y_test = keras.utils.to_categorical(y_test-1, num_classes= number_of_classes)\n",
    "\n",
    "# Train and test\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=64) #batch 32, 64, 128, 256, 512\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Test score:', score\n",
    "print'Test accuracy:', acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
